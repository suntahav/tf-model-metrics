{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f2abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from inspect import signature, Parameter\n",
    "import numpy as np\n",
    "import time\n",
    "import tf_slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb591f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.profiler.model_analyzer import profile \n",
    "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69ec62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4e8ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input#tf.keras.applications.vgg19.preprocess_input\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
    "                                            include_top=False,\n",
    "                                            weights='imagenet')\n",
    "# base_model = tf.keras.models.load_model('mobv3model.h5')\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(100)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.SGD(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee3d2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_flops(model):\n",
    "    forward_pass = tf.function(\n",
    "        model.call,\n",
    "        input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
    "\n",
    "    graph_info = profile(forward_pass.get_concrete_function().graph,\n",
    "                            options=ProfileOptionBuilder.float_operation())\n",
    "    flops = graph_info.total_float_ops / 2e9 \n",
    "    print('Flops: {:,}'.format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "197222da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flops: 0.29980421\n"
     ]
    }
   ],
   "source": [
    "get_total_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "621b9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeFlops():\n",
    "    def __init__(self):\n",
    "        self._call_sign = signature(self)\n",
    "        \n",
    "    def get_temp_model(self, model):\n",
    "        weights = model.get_weights()\n",
    "        new_model = tf.compat.v1.keras.models.clone_model(model)\n",
    "        new_model.build(model.input_shape)\n",
    "        new_model.set_weights(weights)\n",
    "        print(new_model)\n",
    "        return new_model\n",
    "    \n",
    "    def can_pipe(self):\n",
    "        \"\"\"\n",
    "        Returns False if its __call__ signature contains *args or **kwargs else True. This is checked\n",
    "        through python introspection module inspect.signature.\n",
    "        \"\"\"\n",
    "        return not any(p.kind is Parameter.VAR_KEYWORD or p.kind is Parameter.VAR_POSITIONAL\n",
    "                       for p in self._call_sign.parameters.values())\n",
    "\n",
    "    def pipe_kwargs_to_call(self, model, data_splits, kwargs):\n",
    "        \"\"\"\n",
    "        Calls itself using `model`, `data_splits` and an arbitrary `kwargs` dict. It uses the\n",
    "        `bind` method of `inspect.Signature` object.\n",
    "        \"\"\"\n",
    "        kwargs = {k: v for k, v in kwargs.items() if k in self._call_sign.parameters.keys()}\n",
    "        bounded_args = self._call_sign.bind(model, data_splits, **kwargs)\n",
    "        return self(**bounded_args.arguments)\n",
    "    def get_bounded_status_keys(self):\n",
    "        return Flops()\n",
    "\n",
    "    def __call__(self, model, img_size=(224,224), batch_size=1, device=Device.CPU, include_weights=True):\n",
    "        temp_model = self.get_temp_model(model)\n",
    "\n",
    "        with tf.device('gpu' if device == Device.GPU else 'cpu'):\n",
    "            return self._compute_flops(temp_model, img_size, batch_size=batch_size, device=device,\n",
    "                                       include_weights=include_weights)\n",
    "\n",
    "    # HAS TO RETURN A TUPLE IN THE SAME ORDER OF STATUSKEYS\n",
    "    def _compute_flops(self, model, img_size, batch_size=1, device=Device.CPU, include_weights=True):\n",
    "        graph = tf.compat.v1.Graph()\n",
    "        # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "        session = tf.compat.v1.Session(graph=graph)  # , config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "        with graph.as_default():\n",
    "            with session.as_default():\n",
    "                temp_model = tf.compat.v1.keras.models.clone_model(model)\n",
    "                loss = tf.keras.losses.MeanSquaredError()\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "                temp_model.compile(optimizer=optimizer, loss=loss)\n",
    "                data = np.random.randn(1,img_size[0], img_size[1], 3)\n",
    "                _ = temp_model(data, training=False)\n",
    "                opts = (tf.compat.v1.profiler.ProfileOptionBuilder(\n",
    "                    tf.compat.v1.profiler.ProfileOptionBuilder.float_operation())\n",
    "                        .with_empty_output()\n",
    "                        .build())\n",
    "                flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=tf.compat.v1.RunMetadata(), cmd='op', options=opts)\n",
    "                session.close()\n",
    "\n",
    "        del session\n",
    "        flops = getattr(flops, 'total_float_ops',\n",
    "                        0) / 2e9  # Giga Flops - Counting only the flops of forward pass\n",
    "\n",
    "        return flops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "25278353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.functional.Functional object at 0x000002119DB0C760>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.302156161"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops = ComputeFlops()\n",
    "flops(model, img_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0eb21471",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execution Time\n",
    "from enum import Enum\n",
    "\n",
    "class Device(Enum):\n",
    "    CPU = 'cpu'\n",
    "    GPU = 'gpu'\n",
    "\n",
    "\n",
    "\n",
    "class ComputeExecutionTime():\n",
    "    def __init__(self):\n",
    "        self._call_sign = signature(self)\n",
    "\n",
    "    def can_pipe(self):\n",
    "        \"\"\"\n",
    "        Returns False if its __call__ signature contains *args or **kwargs else True. This is checked\n",
    "        through python introspection module inspect.signature.\n",
    "        \"\"\"\n",
    "        return not any(p.kind is Parameter.VAR_KEYWORD or p.kind is Parameter.VAR_POSITIONAL\n",
    "                       for p in self._call_sign.parameters.values())\n",
    "\n",
    "    def pipe_kwargs_to_call(self, model, data_splits, kwargs):\n",
    "        \"\"\"\n",
    "        Calls itself using `model`, `data_splits` and an arbitrary `kwargs` dict. It uses the\n",
    "        `bind` method of `inspect.Signature` object.\n",
    "        \"\"\"\n",
    "        kwargs = {k: v for k, v in kwargs.items() if k in self._call_sign.parameters.keys()}\n",
    "        bounded_args = self._call_sign.bind(model, data_splits, **kwargs)\n",
    "        return self(**bounded_args.arguments)\n",
    "    \n",
    "    def get_bounded_status_keys(self):\n",
    "        return ExecutionTime()\n",
    "    \n",
    "    def get_temp_model(self, model):\n",
    "        weights = model.get_weights()\n",
    "        new_model = tf.keras.models.clone_model(model)\n",
    "        new_model.build(model.input_shape)\n",
    "        new_model.set_weights(weights)\n",
    "        return new_model\n",
    "\n",
    "    def __call__(self, model, input_shape=(224,224), split='train', batch_size=1, device=Device.CPU):\n",
    "        temp_model = self.get_temp_model(model)\n",
    "        device = 'gpu' if device == Device.GPU else 'cpu'\n",
    "        with tf.device(device):\n",
    "            return self._compute_exectime(temp_model, input_shape, batch_size=batch_size)\n",
    "\n",
    "    def _compute_exectime(self, model, input_shape, batch_size=1):\n",
    "        tnum = np.random.randn(batch_size, input_shape[0], input_shape[1], 3)\n",
    "\n",
    "        # START BENCHMARKING\n",
    "        steps = 10\n",
    "        fp_time = 0.\n",
    "\n",
    "        # DRY RUNS\n",
    "        for i in range(steps):\n",
    "            _ = model(tnum, training=False)\n",
    "\n",
    "        class timecallback(tf.keras.callbacks.Callback):\n",
    "            def __init__(self):\n",
    "                self.batch_times = 0\n",
    "                self.step_time_start_batch = 0\n",
    "\n",
    "            def on_predict_batch_begin(self, batch, logs=None):\n",
    "                self.step_time_start_batch = time.perf_counter()\n",
    "\n",
    "            def on_predict_batch_end(self, batch, logs=None):\n",
    "                self.batch_times = time.perf_counter() - self.step_time_start_batch\n",
    "\n",
    "        tt = time.perf_counter()\n",
    "        ctlTime = time.perf_counter() - tt\n",
    "        tcb = timecallback()\n",
    "        for i in range(steps):\n",
    "            _ = model.predict(tnum, batch_size=batch_size, callbacks=[tcb])\n",
    "            if i > 0:\n",
    "                fp_time += (tcb.batch_times - ctlTime)\n",
    "        fp_time = fp_time / (steps - 1) / batch_size\n",
    "        execution_time = fp_time * 1000\n",
    "        return execution_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b4024541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.320055555804476\n"
     ]
    }
   ],
   "source": [
    "timer = ComputeExecutionTime()\n",
    "# data_splits = make_random_datasplits((224,224))\n",
    "# print(model)\n",
    "exectime = timer(model, input_shape=(224,224))\n",
    "print(exectime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39171b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSize():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "        \n",
    "    def get_value(self):\n",
    "        \"\"\"\n",
    "        Optionally rescale the value. Mostly used for formatting when sending to pretty format on stdout\n",
    "        \"\"\"\n",
    "        return self.value\n",
    "        \n",
    "    NAME = 'model_size'\n",
    "\n",
    "    @staticmethod\n",
    "    def description():\n",
    "        return \"Memory consumed by the parameters (weights and biases) of the model\"\n",
    "\n",
    "    @staticmethod\n",
    "    def friendly_name():\n",
    "        return \"Model Size\"\n",
    "\n",
    "    def get_comparative(self):\n",
    "        return Comparative.RECIPROCAL\n",
    "\n",
    "    # TODO this should be dynamic\n",
    "    def get_units(self):\n",
    "        return 'MB'\n",
    "\n",
    "class MemoryFootprint():\n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "    \n",
    "    def get_value(self):\n",
    "        \"\"\"\n",
    "        Optionally rescale the value. Mostly used for formatting when sending to pretty format on stdout\n",
    "        \"\"\"\n",
    "        return self.value\n",
    "    \n",
    "    NAME = 'memory_footprint'\n",
    "\n",
    "    @staticmethod\n",
    "    def description():\n",
    "        return \"Total memory consumed by parameters and activations per single image (batch_size=1)\"\n",
    "\n",
    "    @staticmethod\n",
    "    def friendly_name():\n",
    "        return \"Memory Footprint\"\n",
    "\n",
    "    def get_comparative(self):\n",
    "        return Comparative.RECIPROCAL\n",
    "\n",
    "    # TODO this should be dynamic\n",
    "    def get_units(self):\n",
    "        return 'MB'\n",
    "\n",
    "class ComputeSize():\n",
    "    def __init__(self):\n",
    "        self._call_sign = signature(self)\n",
    "\n",
    "    def can_pipe(self):\n",
    "        \"\"\"\n",
    "        Returns False if its __call__ signature contains *args or **kwargs else True. This is checked\n",
    "        through python introspection module inspect.signature.\n",
    "        \"\"\"\n",
    "        return not any(p.kind is Parameter.VAR_KEYWORD or p.kind is Parameter.VAR_POSITIONAL\n",
    "                       for p in self._call_sign.parameters.values())\n",
    "\n",
    "    def pipe_kwargs_to_call(self, model, data_splits, kwargs):\n",
    "        \"\"\"\n",
    "        Calls itself using `model`, `data_splits` and an arbitrary `kwargs` dict. It uses the\n",
    "        `bind` method of `inspect.Signature` object.\n",
    "        \"\"\"\n",
    "        kwargs = {k: v for k, v in kwargs.items() if k in self._call_sign.parameters.keys()}\n",
    "        bounded_args = self._call_sign.bind(model, data_splits, **kwargs)\n",
    "        return self(**bounded_args.arguments)\n",
    "\n",
    "    def get_temp_model(self, model):\n",
    "        weights = model.get_weights()\n",
    "        new_model = tf.keras.models.clone_model(model)\n",
    "        new_model.build(model.input_shape)\n",
    "        new_model.set_weights(weights)\n",
    "        return new_model\n",
    "\n",
    "    @classmethod\n",
    "    def _get_bounded_status_keys_cls(cls):\n",
    "        return ModelSize, MemoryFootprint\n",
    "\n",
    "    def get_bounded_status_keys(self):\n",
    "        sk_cls = self._get_bounded_status_keys_cls()\n",
    "        rval = tuple(cls() for cls in sk_cls)\n",
    "        return rval\n",
    "\n",
    "    def __call__(self, model, batch_size=1, device=Device.CPU, include_weights=True):\n",
    "        sk_cls = self._get_bounded_status_keys_cls()\n",
    "        temp_model = self.get_temp_model(model)\n",
    "\n",
    "        with tf.device('gpu' if device == Device.GPU else 'cpu'):\n",
    "            rval = self._compute_size(temp_model, batch_size=batch_size,\n",
    "                                      include_weights=include_weights)\n",
    "\n",
    "        assert len(sk_cls) == len(rval)\n",
    "        return {x.NAME: y for x, y in zip(sk_cls, rval)}\n",
    "\n",
    "    # HAS TO RETURN A TUPLE IN THE SAME ORDER OF STATUSKEYS\n",
    "    def _compute_size(self, model, batch_size=1, include_weights=True):\n",
    "        model_vars = model.trainable_variables\n",
    "        _, model_size = slim.model_analyzer.analyze_vars(model_vars, print_info=False)\n",
    "\n",
    "        activation_size = 0\n",
    "        for layer in model.layers:\n",
    "            output_shape = layer.output_shape\n",
    "            if isinstance(output_shape, list):\n",
    "                for osp in output_shape:\n",
    "                    osp = [x for x in osp if x is not None]\n",
    "                    activation_size += np.product(osp) * batch_size * 4  # 4 bytes\n",
    "            if isinstance(output_shape, tuple):\n",
    "                output_shape = [x for x in output_shape if x is not None]\n",
    "                activation_size += np.product(output_shape) * batch_size * 4  # 4 bytes\n",
    "\n",
    "        total_input_size = 0\n",
    "        input_shape = model.layers[0].input_shape\n",
    "        if isinstance(input_shape, list):\n",
    "            for isp in input_shape:\n",
    "                isp = [x for x in isp if x is not None]\n",
    "                total_input_size += np.product(isp) * batch_size * 4  # 4 bytes\n",
    "        if isinstance(input_shape, tuple):\n",
    "            input_shape = [x for x in input_shape if x is not None]\n",
    "            total_input_size += np.product(input_shape) * batch_size * 4  # 4 bytes\n",
    "\n",
    "        memory_footprint = int(activation_size + total_input_size)\n",
    "        if include_weights:\n",
    "            memory_footprint += model_size\n",
    "        model_size = abs(model_size / (1024 ** 2.))  # Convert bytes to MB\n",
    "        memory_footprint = abs(memory_footprint / (1024 ** 2.))  # Convert bytes to MB\n",
    "\n",
    "        return model_size, memory_footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6ae842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_size': 8.972061157226562, 'memory_footprint': 11.518341064453125}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = ComputeSize()\n",
    "size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0da5b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeLayerwiseSummary():\n",
    "    def __init__(self):\n",
    "        self._call_sign = signature(self)\n",
    "\n",
    "    def can_pipe(self):\n",
    "        \"\"\"\n",
    "        Returns False if its __call__ signature contains *args or **kwargs else True. This is checked\n",
    "        through python introspection module inspect.signature.\n",
    "        \"\"\"\n",
    "        return not any(p.kind is Parameter.VAR_KEYWORD or p.kind is Parameter.VAR_POSITIONAL\n",
    "                       for p in self._call_sign.parameters.values())\n",
    "\n",
    "    def pipe_kwargs_to_call(self, model, data_splits, kwargs):\n",
    "        \"\"\"\n",
    "        Calls itself using `model`, `data_splits` and an arbitrary `kwargs` dict. It uses the\n",
    "        `bind` method of `inspect.Signature` object.\n",
    "        \"\"\"\n",
    "        kwargs = {k: v for k, v in kwargs.items() if k in self._call_sign.parameters.keys()}\n",
    "        bounded_args = self._call_sign.bind(model, data_splits, **kwargs)\n",
    "        return self(**bounded_args.arguments)\n",
    "    \n",
    "    def get_temp_model(self, model):\n",
    "        weights = model.get_weights()\n",
    "        new_model = tf.keras.models.clone_model(model)\n",
    "        new_model.build(model.input_shape)\n",
    "        new_model.set_weights(weights)\n",
    "        return new_model\n",
    "    \n",
    "    def __call__(self, model, batch_size=1, device=Device.CPU, include_weights=True):\n",
    "        temp_model = self.get_temp_model(model)\n",
    "\n",
    "        with tf.device('gpu' if device == Device.GPU else 'cpu'):\n",
    "            return self._compute_layerwise_summary(temp_model, batch_size=batch_size,\n",
    "                                                   device=device,\n",
    "                                                   include_weights=include_weights)\n",
    "\n",
    "    # HAS TO RETURN A TUPLE IN THE SAME ORDER OF STATUSKEYS\n",
    "    def _compute_layerwise_summary(self, model, batch_size=1, device=Device.CPU,\n",
    "                                   include_weights=True):\n",
    "        stringlist = []\n",
    "        model.summary(print_fn=stringlist.append)\n",
    "        stringlist = stringlist[1:-4]\n",
    "        summary_str = \"\\n\".join(stringlist)\n",
    "\n",
    "        return summary_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21c2f7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv_7 (TFOpLambd (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract_7 (TFOpLamb (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               128100    \n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "summary = ComputeLayerwiseSummary()\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "152bb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeParams():\n",
    "    def __init__(self):\n",
    "        self._call_sign = signature(self)\n",
    "\n",
    "    def can_pipe(self):\n",
    "        \"\"\"\n",
    "        Returns False if its __call__ signature contains *args or **kwargs else True. This is checked\n",
    "        through python introspection module inspect.signature.\n",
    "        \"\"\"\n",
    "        return not any(p.kind is Parameter.VAR_KEYWORD or p.kind is Parameter.VAR_POSITIONAL\n",
    "                       for p in self._call_sign.parameters.values())\n",
    "\n",
    "    def pipe_kwargs_to_call(self, model, data_splits, kwargs):\n",
    "        \"\"\"\n",
    "        Calls itself using `model`, `data_splits` and an arbitrary `kwargs` dict. It uses the\n",
    "        `bind` method of `inspect.Signature` object.\n",
    "        \"\"\"\n",
    "        kwargs = {k: v for k, v in kwargs.items() if k in self._call_sign.parameters.keys()}\n",
    "        bounded_args = self._call_sign.bind(model, data_splits, **kwargs)\n",
    "        return self(**bounded_args.arguments)\n",
    "    \n",
    "    def get_temp_model(self, model):\n",
    "        weights = model.get_weights()\n",
    "        new_model = tf.keras.models.clone_model(model)\n",
    "        new_model.build(model.input_shape)\n",
    "        new_model.set_weights(weights)\n",
    "        return new_model\n",
    "\n",
    "    def __call__(self, model, batch_size=1, device=Device.CPU, include_weights=True):\n",
    "        temp_model = self.get_temp_model(model)\n",
    "\n",
    "        with tf.device('gpu' if device == Device.GPU else 'cpu'):\n",
    "            return self._compute_params(temp_model, batch_size=batch_size, device=device,\n",
    "                                        include_weights=include_weights)\n",
    "\n",
    "    # HAS TO RETURN A TUPLE IN THE SAME ORDER OF STATUSKEYS\n",
    "    def _compute_params(self, model, batch_size=1, device=Device.CPU, include_weights=True):\n",
    "        model_vars = model.trainable_variables\n",
    "        num_params, _ = slim.model_analyzer.analyze_vars(model_vars, print_info=False)\n",
    "\n",
    "        params = num_params / 1e6  # Million Flops\n",
    "        return str(params)+' Million'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9eaab5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.351972 Million'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = ComputeParams()\n",
    "param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbdb655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "# x_train = x_train.astype('float32') / 255\n",
    "# x_test = x_test.astype('float32') / 255\n",
    "# y_train = np.eye(100)[y_train.reshape(-1)]\n",
    "# y_test = np.eye(100)[y_test.reshape(-1)]\n",
    "data = make_random_datasplits((224,224))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573a3527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12867108"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras_flops import get_flops\n",
    "\n",
    "get_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0841796",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "img_size = (32,32)\n",
    "data = np.random.randn(1,img_size[0], img_size[1], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6454dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your Layer or Model is in an invalid state. This can happen for the following cases:\n 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.\n2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the implementation of <class 'tensorflow.python.keras.engine.functional.Functional'> and its bases.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:666\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    642\u001b[0m   \u001b[38;5;124;03m\"\"\"Wraps `call`, applying pre- and post-processing steps.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03m  Arguments:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    RuntimeError: if `super().__init__()` was not called in the constructor.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_built_as_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    668\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_thread_local\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must call `super().__init__()` in the layer constructor.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:839\u001b[0m, in \u001b[0;36mLayer._assert_built_as_v1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_built_as_v1\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    838\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_originally_built_as_v1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour Layer or Model is in an invalid state. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis can happen for the following cases:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1. You might be interleaving estimator/non-estimator models or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterleaving models/layers made in tf.compat.v1.Graph.as_default() \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    844\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith models/layers created outside of it. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    845\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConverting a model to an estimator (via model_to_estimator) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalidates all models/layers made before the conversion (even \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mif they were not the model converted to an estimator). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimilarly, making a layer or a model inside a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma tf.compat.v1.Graph invalidates all layers/models you previously \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmade outside of the graph.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2. You might be using a custom keras layer implementation with \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m custom __init__ which didn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt call super().__init__. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Please check the implementation of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and its bases.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    854\u001b[0m         (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m),))\n",
      "\u001b[1;31mValueError\u001b[0m: Your Layer or Model is in an invalid state. This can happen for the following cases:\n 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.\n2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the implementation of <class 'tensorflow.python.keras.engine.functional.Functional'> and its bases."
     ]
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a040bcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
